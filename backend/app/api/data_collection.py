"""
ãƒ‡ãƒ¼ã‚¿åé›†APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆç®¡ç†è€…å°‚ç”¨ï¼‰
"""
import os
import tempfile
from fastapi import APIRouter, Depends, HTTPException, status, UploadFile, File
from sqlalchemy.orm import Session
from app.dependencies import get_db, get_current_admin_user
from app.models.user import User
from app.schemas.data_collection import (
    DataCollectionRequest,
    YouTubeCollectionResponse,
    LocationUpdateRequest,
    LocationUpdateResponse,
    SNSCollectionRequest,
    SNSCollectionResponse,
    SpotImportRequest,
    SNSImportRequest,
    SpotImportResponse,
    CSVImportResponse
)
from app.services.youtube_collection_service import collect_youtube_data
from app.services.geocoding_service import add_location_to_places
from app.services.sns_collection_service import collect_trending_topics, collect_sns_data_with_summary
from app.services.spot_import_service import (
    import_spots_from_youtube_data,
    import_spots_from_sns_data,
    add_location_to_existing_spots,
    import_spots_from_csv_file
)
from app.config import settings
from app.utils.error_handler import log_error

router = APIRouter(prefix="/api/admin/data-collection", tags=["ãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆç®¡ç†è€…ï¼‰"])


@router.post("/youtube", response_model=YouTubeCollectionResponse)
async def collect_youtube_videos(
    request: DataCollectionRequest,
    current_user: User = Depends(get_current_admin_user),
    db: Session = Depends(get_db)
):
    """
    YouTubeãƒ‡ãƒ¼ã‚¿åé›†ã‚’å®Ÿè¡Œï¼ˆç®¡ç†è€…å°‚ç”¨ï¼‰
    
    YouTube Data APIã‹ã‚‰å‹•ç”»ã‚’å–å¾—ã—ã€Gemini APIã§è¦ç´„ã—ã¾ã™ã€‚
    """
    if not settings.DATA_COLLECTION_ENABLED:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="ãƒ‡ãƒ¼ã‚¿åé›†æ©Ÿèƒ½ãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã¾ã™ã€‚DATA_COLLECTION_ENABLEDã‚’Trueã«è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )
    
    if not settings.YOUTUBE_API_KEY:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="YOUTUBE_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
        )
    
    if not settings.GEMINI_API_KEY:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="GEMINI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
        )
    
    try:
        result = collect_youtube_data(
            prefecture=request.prefecture,
            keywords_config_path=request.keywords_config_path,
            max_results_per_keyword=request.max_results_per_keyword,
            stop_on_quota_exceeded=True
        )
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”Ÿæˆ
        message_parts = []
        if result["total_videos"] > 0:
            message_parts.append(f"{result['total_videos']}ä»¶ã®å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¾ã—ãŸã€‚")
        
        if result["quota_exceeded"]:
            message_parts.append(
                f"âš ï¸ YouTube APIã®ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚"
                f"å‡¦ç†æ¸ˆã¿: {result['successful_keywords']}/{result['total_keywords']}ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€‚"
                f"æ®‹ã‚Š{result['quota_exceeded_keywords']}ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯å‡¦ç†ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
            )
            message_parts.append(
                "ğŸ’¡ å¯¾å‡¦æ³•: 1) max_results_per_keywordã‚’æ¸›ã‚‰ã™ã€2) ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ã‚’æ¸›ã‚‰ã™ã€"
                "3) ã‚¯ã‚©ãƒ¼ã‚¿ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã‚‹ã¾ã§å¾…ã¤ï¼ˆ24æ™‚é–“ã”ã¨ï¼‰ã€4) è¤‡æ•°ã®APIã‚­ãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹"
            )
        
        if result["failed_keywords"] > 0:
            message_parts.append(f"âš ï¸ {result['failed_keywords']}ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        
        if result["total_videos"] > 0:
            message_parts.append(
                "ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹ã«ã¯ã€åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’"
                " POST /api/admin/data-collection/import-spots ã«é€ä¿¡ã—ã¦ãã ã•ã„ã€‚"
            )
        
        message = " ".join(message_parts) if message_parts else "ãƒ‡ãƒ¼ã‚¿åé›†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚"
        
        return YouTubeCollectionResponse(
            success=True,
            total_keywords=result["total_keywords"],
            total_videos=result["total_videos"],
            results=result["results"],
            message=message,
            quota_exceeded=result["quota_exceeded"],
            quota_exceeded_keywords=result["quota_exceeded_keywords"],
            successful_keywords=result["successful_keywords"],
            failed_keywords=result["failed_keywords"]
        )
    except Exception as e:
        log_error("YOUTUBE_COLLECTION_API_ERROR", str(e), {"prefecture": request.prefecture})
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"YouTubeãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {str(e)}"
        )


@router.post("/location", response_model=LocationUpdateResponse)
async def update_location_data(
    request: LocationUpdateRequest,
    current_user: User = Depends(get_current_admin_user),
    db: Session = Depends(get_db)
):
    """
    æ—¢å­˜ã®Spotã«ä½ç½®æƒ…å ±ã‚’ä»˜ä¸ï¼ˆç®¡ç†è€…å°‚ç”¨ï¼‰
    
    OpenCage Geocoding APIã‚’ä½¿ç”¨ã—ã¦ä½ç½®æƒ…å ±ã‚’å–å¾—ã—ã€Spotã«ä»˜ä¸ã—ã¾ã™ã€‚
    """
    if not settings.DATA_COLLECTION_ENABLED:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="ãƒ‡ãƒ¼ã‚¿åé›†æ©Ÿèƒ½ãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã¾ã™ã€‚DATA_COLLECTION_ENABLEDã‚’Trueã«è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )
    
    if not settings.OPENCAGE_API_KEY:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="OPENCAGE_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
        )
    
    try:
        result = add_location_to_existing_spots(
            db=db,
            spot_ids=request.spot_ids,
            prefecture=request.prefecture
        )
        
        return LocationUpdateResponse(
            success=True,
            updated=result["updated"],
            errors=result["errors"],
            skipped=result["skipped"],
            total_processed=result["total_processed"],
            message=f"{result['updated']}ä»¶ã®Spotã«ä½ç½®æƒ…å ±ã‚’ä»˜ä¸ã—ã¾ã—ãŸã€‚"
        )
    except Exception as e:
        log_error("LOCATION_UPDATE_API_ERROR", str(e), {"prefecture": request.prefecture})
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ä½ç½®æƒ…å ±ä»˜ä¸ã‚¨ãƒ©ãƒ¼: {str(e)}"
        )


@router.post("/sns", response_model=SNSCollectionResponse)
async def collect_sns_data(
    request: SNSCollectionRequest,
    current_user: User = Depends(get_current_admin_user),
    db: Session = Depends(get_db)
):
    """
    SNS/Webæ¤œç´¢ãƒ‡ãƒ¼ã‚¿åé›†ã‚’å®Ÿè¡Œï¼ˆç®¡ç†è€…å°‚ç”¨ï¼‰
    
    Googleãƒ‹ãƒ¥ãƒ¼ã‚¹RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰è¨˜äº‹ã‚’å–å¾—ã—ã€Gemini APIã§è¦ç´„ã—ã¾ã™ã€‚
    """
    if not settings.DATA_COLLECTION_ENABLED:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="ãƒ‡ãƒ¼ã‚¿åé›†æ©Ÿèƒ½ãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã¾ã™ã€‚DATA_COLLECTION_ENABLEDã‚’Trueã«è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )
    
    if not settings.GEMINI_API_KEY:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="GEMINI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
        )
    
    try:
        result = collect_sns_data_with_summary(
            keyword=request.keyword,
            max_results=20  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæœ€å¤§20ä»¶
        )
        
        return SNSCollectionResponse(
            success=True,
            count=len(result["results"]),
            results=result["results"],
            message=f"{len(result['results'])}ä»¶ã®ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚’åé›†ãƒ»è¦ç´„ã—ã¾ã—ãŸã€‚"
        )
    except Exception as e:
        log_error("SNS_COLLECTION_API_ERROR", str(e), {"keyword": request.keyword})
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"SNS/Webæ¤œç´¢ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {str(e)}"
        )


@router.post("/import-spots", response_model=SpotImportResponse)
async def import_spots(
    request: SpotImportRequest,
    current_user: User = Depends(get_current_admin_user),
    db: Session = Depends(get_db)
):
    """
    YouTubeåé›†ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰Spotã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆç®¡ç†è€…å°‚ç”¨ï¼‰
    
    YouTubeåé›†ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦Spotãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¾ã™ã€‚
    """
    if not settings.DATA_COLLECTION_ENABLED:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="ãƒ‡ãƒ¼ã‚¿åé›†æ©Ÿèƒ½ãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã¾ã™ã€‚DATA_COLLECTION_ENABLEDã‚’Trueã«è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )
    
    try:
        result = import_spots_from_youtube_data(
            db=db,
            youtube_data=request.youtube_data,
            prefecture=request.prefecture
        )
        
        return SpotImportResponse(
            success=True,
            imported=result["imported"],
            errors=result["errors"],
            skipped=result["skipped"],
            total_processed=result["total_processed"],
            message=f"{result['imported']}ä»¶ã®Spotã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸã€‚"
        )
    except Exception as e:
        log_error("SPOT_IMPORT_API_ERROR", str(e), {"prefecture": request.prefecture})
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Spotã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}"
        )


@router.post("/import-spots-from-sns", response_model=SpotImportResponse)
async def import_spots_from_sns(
    request: SNSImportRequest,
    current_user: User = Depends(get_current_admin_user),
    db: Session = Depends(get_db)
):
    """
    SNSåé›†ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰Spotã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆç®¡ç†è€…å°‚ç”¨ï¼‰
    
    SNSåé›†ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦Spotãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¾ã™ã€‚
    é‡è¤‡ã™ã‚‹SpotãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã€æƒ…å ±ã‚’ãƒãƒ¼ã‚¸ï¼ˆçµ±åˆï¼‰ã—ã¾ã™ã€‚
    """
    if not settings.DATA_COLLECTION_ENABLED:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="ãƒ‡ãƒ¼ã‚¿åé›†æ©Ÿèƒ½ãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã¾ã™ã€‚DATA_COLLECTION_ENABLEDã‚’Trueã«è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )
    
    try:
        result = import_spots_from_sns_data(
            db=db,
            sns_data=request.sns_data,
            prefecture=request.prefecture
        )
        
        return SpotImportResponse(
            success=True,
            imported=result["imported"],
            errors=result["errors"],
            skipped=result["skipped"],
            total_processed=result["total_processed"],
            message=f"{result['imported']}ä»¶ã®Spotã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ/ãƒãƒ¼ã‚¸ã—ã¾ã—ãŸã€‚"
        )
    except Exception as e:
        log_error("SNS_SPOT_IMPORT_API_ERROR", str(e), {"prefecture": request.prefecture})
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"SNS Spotã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}"
        )


@router.post("/import-spots-from-csv", response_model=CSVImportResponse)
async def import_spots_from_csv(
    file: UploadFile = File(...),
    current_user: User = Depends(get_current_admin_user),
    db: Session = Depends(get_db)
):
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Spotã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆç®¡ç†è€…å°‚ç”¨ï¼‰
    
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€Spotãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¾ã™ã€‚
    é‡è¤‡ã™ã‚‹SpotãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ï¼ˆæ—¢å­˜æƒ…å ±ã‚’ä¿æŒï¼‰ã€‚
    """
    if not settings.DATA_COLLECTION_ENABLED:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="ãƒ‡ãƒ¼ã‚¿åé›†æ©Ÿèƒ½ãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã¾ã™ã€‚DATA_COLLECTION_ENABLEDã‚’Trueã«è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )
    
    # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã®æ¤œè¨¼
    if not file.filename.endswith('.csv'):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã§ã™ã€‚"
        )
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    temp_file_path = None
    try:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        with tempfile.NamedTemporaryFile(mode='wb', delete=False, suffix='.csv') as temp_file:
            temp_file_path = temp_file.name
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’æ›¸ãè¾¼ã‚€
            content = await file.read()
            temp_file.write(content)
        
        # CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å®Ÿè¡Œ
        result = import_spots_from_csv_file(
            db=db,
            csv_file_path=temp_file_path
        )
        
        return CSVImportResponse(
            success=True,
            imported=result["imported"],
            errors=result["errors"],
            skipped=result["skipped"],
            total_processed=result["total_processed"],
            message=f"{result['imported']}ä»¶ã®Spotã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸã€‚"
        )
    except FileNotFoundError as e:
        log_error("CSV_FILE_NOT_FOUND", str(e))
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {str(e)}"
        )
    except Exception as e:
        log_error("CSV_SPOT_IMPORT_API_ERROR", str(e), {"filename": file.filename})
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"CSV Spotã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}"
        )
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        if temp_file_path and os.path.exists(temp_file_path):
            try:
                os.unlink(temp_file_path)
            except Exception:
                pass  # å‰Šé™¤ã«å¤±æ•—ã—ã¦ã‚‚ç¶šè¡Œ

